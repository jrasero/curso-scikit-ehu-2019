{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Carga las librerías de nummpy, pandas y matplotlib con el nombre de siempre**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tu código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lee los datos adjuntos a este notebook, creando un dataframe de pandas con el nombre que quieras. Ajusta el argumento na_values a '?' ****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tu código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Redefine el dataframe anterior quitando las columnas [\"Date\",\"Location\", \"RainToday\", \"RISK_MM\"]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tu código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**La data contiene huecos. Quítalos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tu código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Las variables 'WindGustDir', 'WindDir3pm', 'WindDir9am' son categóricas. Crea dummy variables, esto es, que sean ortogonales usando un one-hot-encoding mediante la funcionalidad `get_dummies` de pandas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tu código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A partir de esta dataset, define una matrix de features X y un vector de labels y**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tu código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Codifica el vector de labels a 0 y 1 usando `LabelEncoder`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tu código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Divide el 80% de los datos para training y el 20% restante para test. Para ello usa la función `train_test_split`, fijando el random_state=0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tu código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importa un clasificador tipo arbol de decision, y crea un objeto de esta clase. Cuando definas el objeto, elige el argumento `random_state` igual a 0, `class_weight` igual a 'balanced'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tu código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ajusta el modelo sobre el train y calcula la accuracy sobre el mismo training y test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tu código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Después de ajustar el clasificador, éste da un atributo llamado \"feature_importances_\" que da un vector con la importancia de cada feature. Plotea la importancia de cada feature usando barras. Puedes usar la function bar dentro de matplotlib. Si tienes alguna duda de cómo usar la función, puedes mirar la documentación**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tu código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vamos a calcular lo anterior para diferentes particiones de los datos. Para ello, primero importa la clase `StratifiedKFold` contenida en el módulo de model_selection. Después, define una variable que sea un objeto de esta clase y que implemente un 5-Fold cross-validation. Fija random_state=0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tu código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calcula la accuracy promedio a través de estos 5 folds**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tu código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hay muchas variables, ¿verdad? Puede que no se necesiten todas. Vamos Mediante realiza un feature selection basado en las importancias dadas por el árbol de decision anterior. El clasificador final será en este caso `Logistic Regression`. Por ello, primero importa la clase que implementa este algoritmo y define un objeto de dicho clasificador al que llamaremos \"log_clf\". Elige random_state=0 y class_weight='balanced' cuando definas este objeto**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tu código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importa la clase `SelectFromModel`, que vamos a usar para seleccionar las features más importantes basado en la importancia de las features en el árbol de decision. Define un objeto de la clase recién importada y llámala \"feat\". No olvides que dicho objeto requiere que le pases el árbol de decision que va a usar para estimar la importancia de la features a seleccionar. Si tienes alguna duda, mira en la documentación**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tu código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Además, algunas features tienen escala diferente. Por ello, importa la clase `MinMaxScaler` y define un objeto a partir de esta clase, llamándola \"scaler\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tu código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vamos a encadenar los tres objetos, que implementan diferentes operaciones, en un sólo objeto. Para ello, importa la clase `Pipeline` y crea un objeto a partir de ella llamada \"pip\". Los pasos van en este orden: primero el reescalado de los datos, después feature selection y por último el clasificador**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tu código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calcula la accuracy promediada de este objeto tipo pipeline usado el cross-validation definido más arriba**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tu código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A veces algunos clasificadores ya implementan esto por construcción y dan un rendimiento mejor. Prueba esto con un clasificador de tipo Random Forest, implementada con el nombre `RandomForestClassifier`. Usa 50 árboles de decisión y acuérdate de elegir random_state=0 y class_weight='balanced'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tu código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(Extra) Repite esto último con la dataset inicial, pero rellenando los NaNs en cada columna con la mediana en sus valores observados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tu código"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
