{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Carga las librerías de nummpy, pandas y matplotlib con el nombre de siempre**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tu código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lee los datos adjuntos a este notebook, creando un dataframe de pandas con el nombre que quieras. Ajusta el argumento na_values a '?' ****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tu código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reescribe el nombre de las columnas a:*'age', 'sex', 'cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal','diagnosis'***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tu código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Muestra las primeras cinco filas del data frame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tu código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Usando un método de pandas, muestra la información sobre los tipos de las variables y el número de valores no nulos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tu código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Usando un método de pandas, muestra la información sobre la estadística descriptiva de cada variable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tu código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Crea una nueva columna \"diagnosis_int\", tal que sea 0 si el valor en la columna \"diangosis\" es cero y 1 en caso contrario**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tu código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Elimina la columna \"diagnosis\" (No os olvidéis de asignar de nuevo el dataframe después de hacer esta operación)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tu código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Renombra la columna \"diagnosis_int\" a \"diagnosis\" (Puedes usar el método \"rename\" de los dataframes de pandas)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tu código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Como siempre, plotea las variables individuales diferenciando su diagnosis. Puedes usar un histograma, barplots, etc...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tu código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define, como siempre, un objeto numpy `X` que contenga los features \"age\", \"ca\" y \"thal\" y un objeto numpy `y` con el target, en este caso, la columna diagnosis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tu código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**La variable \"ca\" tiene NaNs. Usa la clase `Imputer` en scikit para reemplazar los NaN por el valor más frecuente**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tu código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A su vez, la variable \"cp\", \"thal\" y \"slope\"  son variables categóricas. Usa la clase `OneHotEncoder` en el módulo preprocessing de scikit para codificar estas categorías (fija el argumento de esta clase llamado `sparse` a False). Mira cómo aumenta el tamaño de los datos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tu código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Crea una partición de los datos train y test, donde el primero tenga el 70% de los datos y el segundo el 30% restante. Puedes usar la función `train_test_split` dentro del módulo `model_selection` scikit usando un random_state=0** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tu código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calcula la performance del clasificador usando un árbol de decisión y random forest. En ambos casos, fija el valor de random_state=0 en clasificador y muestra los resultados variando el hiperparámetro max_depth**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tu código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Otros clasificadores necesitan que las variables tengan la misma escala. Vuelve a hacer todo el preprocesing anterior sobre X ( Imputer y one hot encoder), añadiendo como último paso la aplicación de la clase `MinMaxScaler` en el módulo de preprocessing de scikit, que permite reescalar los datos entre 0 y 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tu código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sobre estos datos reescalados, vuelve a crear una partición de los datos train y test, donde el primero tenga el 70% de los datos y el segundo el 30% restante. Puedes usar la función `train_test_split` dentro del módulo `model_selection` de scikit usando un random_state=0** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tu código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calcula la performance del clasificador usando logistic regression, support vector machines y k-nearest neighbors. En todos los casos, muestra los resultados variando los hiperparámetros de los algoritmos (por ejemplo, C en los dos primeros y n_neighbors en el último)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tu código"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
