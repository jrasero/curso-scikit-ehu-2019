{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### En este notebook vamos a ver las diferentes herramientas que hemos aprendido para evaluar el rendimiento del clasificador y la selección de aquel modelo con el mayor poder predictivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_url = \"https://raw.githubusercontent.com/jrasero/curso-scikit-ehu-2019/master/datasets/pima-indians-diabetes.csv\"\n",
    "data = pd.read_csv(path_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = [\"pregnancies\", \"glucose\", \"blood_pressure\", \n",
    "              \"skin_thickness\",\"insulin\",\"bmi\",\"Diabetes_Pedigree_Function\",\n",
    "              \"age\",\"outcome\"]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos nuestra matriz features y vector de targets\n",
    "X = data.dropna().drop(columns=[\"outcome\"]).values\n",
    "y = data.dropna().outcome.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metodo holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a usar un Árbol de decision. \n",
    "# Primero, creamos un objeto de la clase de este clasificador\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf= DecisionTreeClassifier(class_weight='balanced',\n",
    "                           random_state=0)\n",
    "# Ajustamos los datos\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Predecimos sobre los mismos datos que hemos usado para ajustar\n",
    "print(clf.score(X,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este resultado anterior es irreal y nada generalizable, ya que hemos usado para la predicción el mismo dataset del ajuste. Como hemos visto, para ver la generalización del modelo, tenemos que dejar una parte de la dataset fuera del ajuste (**Método holdout**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "print(\" El rendimiento sobre el training:\" ,clf.score(X_train,y_train))\n",
    "print(\" El rendimiento sobre el test:\", clf.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cómo dependen los resultados de los parámetros del algoritmo y el tamaño de la partición?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores=[]\n",
    "test_scores=[]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=0)\n",
    "\n",
    "max_depth = np.arange(2,10)\n",
    "for depth in max_depth:\n",
    "    \n",
    "    clf = DecisionTreeClassifier(max_depth=depth, \n",
    "                                 class_weight='balanced',\n",
    "                                 random_state=0)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    train_scores.append(clf.score(X_train,y_train))\n",
    "    test_scores.append(clf.score(X_test,y_test))\n",
    "    \n",
    "    \n",
    "plt.plot(np.asarray(train_scores))\n",
    "plt.plot(np.asarray(test_scores))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podríamos hacer lo mismo usando la funcionalidad `validation_curve` de scikit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "train_scores, test_scores = validation_curve(\n",
    "    DecisionTreeClassifier(class_weight='balanced',\n",
    "                           random_state=0), X, y, param_name=\"max_depth\", \n",
    "    param_range=max_depth,\n",
    "    cv=10, scoring=\"accuracy\", n_jobs=1)\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.grid()\n",
    "\n",
    "plt.fill_between(max_depth, \n",
    "                 train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                 color=\"r\")\n",
    "plt.fill_between(max_depth, \n",
    "                 test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "plt.plot(max_depth, train_scores_mean, 'o-', color=\"r\",\n",
    "         label=\"Training score\")\n",
    "plt.plot(max_depth, test_scores_mean, 'o-', color=\"g\",\n",
    "         label=\"Cross-validation score\")\n",
    "\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podríamos estar interesados en ver cómo varía nuestro modelo con el tamaño de nuestra dataset. Se usa para esto la funcionalidad `learning_curve` de scikit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "train_sizes , train_scores, test_scores = learning_curve(\n",
    "    DecisionTreeClassifier(max_depth=5,\n",
    "                           class_weight='balanced',\n",
    "                           random_state=0), \n",
    "    X, y, \n",
    "    train_sizes=np.linspace(.1, 1.0, 5),\n",
    "    cv=10, scoring=\"accuracy\", n_jobs=1)\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.grid()\n",
    "\n",
    "plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                 color=\"r\")\n",
    "plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "         label=\"Training score\")\n",
    "plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "         label=\"Cross-validation score\")\n",
    "\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a definir un cross-validation con 10 folds estratificados\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=10, random_state=0)\n",
    "\n",
    "# Veamos cómo es cada fold\n",
    "print('{} {}'.format('Training set observations', 'Testing set observations'))\n",
    "for train_index, test_index in skf.split(X, y):                                     \n",
    "    print('Num obs training: {0}, con {1} de la calse negativa y {2} de la clase positiva. Num obs en test es: {3}'.format(len(train_index), \n",
    "                                                    sum(y[train_index]==0),\n",
    "                                                    sum(y[train_index]==1), \n",
    "                                                    len(test_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf= DecisionTreeClassifier(class_weight='balanced',\n",
    "                           random_state=0)\n",
    "\n",
    "scores = cross_val_score(clf, X, y, cv=skf, \n",
    "                         scoring='accuracy')\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = cross_val_predict(clf, X, y, cv=skf)\n",
    "print(accuracy_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mejoras a cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Repeated cross-validation**\n",
    "\n",
    "- Repetir cross-validation varias veces ( con **differentes particiones aleatorias** de los datos) y promediar los resultados\n",
    "- Estimaciones más fiables puesto que se **reduce la variabiliad** asociada con un solo intento de cross-validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedKFold\n",
    "rcv = RepeatedKFold(n_splits=10, n_repeats=5, random_state=0)\n",
    "clf = DecisionTreeClassifier(class_weight='balanced',\n",
    "                           random_state=0)\n",
    "scores = cross_val_score(clf, X, y, cv=rcv, scoring='accuracy')\n",
    "print(len(scores))\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_scores = []\n",
    "rcv = RepeatedKFold(n_splits=10, n_repeats=5, random_state=0)\n",
    "for depth in max_depth:\n",
    "    clf = DecisionTreeClassifier(max_depth=depth,\n",
    "                                 class_weight='balanced',\n",
    "                                 random_state=0)    \n",
    "    \n",
    "    scores = cross_val_score(clf, X, y, cv=rcv, scoring='accuracy')\n",
    "    depth_scores.append(np.mean(scores))\n",
    "\n",
    "print(depth_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(max_depth, depth_scores)\n",
    "plt.xlabel('Value of depth for Decision Tree')\n",
    "plt.ylabel('Cross-Validated Accuracy')\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploración de los hiperparámetros del clasificador\n",
    "\n",
    "Ya hemos visto que en scikit esto se puede hacer mediante la clase `GridSearchCV` y `RandomizedSearchCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un grid con los parámetros sobre los que probar el clasificador\n",
    "# El grid es siempre un diccionario\n",
    "param_grid = {'max_depth':max_depth}\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos un objeto de la clase GridSearchCV y le pasamos\n",
    "# el clasificador, el grid, un esquema de cross-validation y \n",
    "# un score que queremos mirar como medida de optimización\n",
    "rcv = RepeatedKFold(n_splits=10, n_repeats=5, random_state=0)\n",
    "grid = GridSearchCV(clf, param_grid, cv=rcv, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustamos los datos, que internamente incorpora un cross-validation\n",
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Los resultados quedan almacenados en cv_results_\n",
    "pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(max_depth, grid.cv_results_['mean_test_score'])\n",
    "plt.xlabel('Value of depth for Decision Tree')\n",
    "plt.ylabel('Cross-Validated Accuracy')\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos mirar las características del mejor modelo\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscando varios parámetros simultáneamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos  otra vez los hiperparámetos\n",
    "max_depth = np.arange(2,10)\n",
    "criterion = ['gini', 'entropy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora nuestro grid está formado por dos parámetros\n",
    "param_grid = {'max_depth': max_depth, \n",
    "              'criterion': criterion}\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos un objeto de la clase GridSearchCV\n",
    "grid = GridSearchCV(clf, param_grid, cv=rcv, scoring='accuracy')\n",
    "grid.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grid.cv_results_).loc[:,['params','mean_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos mirar las características del mejor modelo\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `RandomizedSearchCV` para reducir la carga computacional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Buscar sobre todas las posibles combinaciones de los diferentes hiperparámetros puede ser muy costoso computacionalmente hablando.\n",
    "- `RandomizedSearchCV` coge un subset de éstos en tantas iteracciones como uno desee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {'max_depth': max_depth, \n",
    "              'criterion': criterion}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_iter controla el número de busquedas sobre los parámetros\n",
    "rand = RandomizedSearchCV(clf, param_dist, cv=rcv, \n",
    "                          scoring='accuracy', n_iter=10, random_state=10)\n",
    "rand.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(rand.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos mirar las características del mejor modelo\n",
    "print(rand.best_score_)\n",
    "print(rand.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
